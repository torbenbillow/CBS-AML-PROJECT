{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/torbenbillow/CBS-AML-PROJECT/blob/main/notebooks/00_welcome.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# IMPORT LIBRARIES"
      ],
      "metadata": {
        "id": "FSKTe-rY5QJL"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "GEVrLPEfeP5M"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import geopandas as gpd\n",
        "from shapely.geometry import Point, Polygon\n",
        "\n",
        "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "from sklearn.linear_model import LinearRegression, Ridge, Lasso, LogisticRegression\n",
        "from sklearn.tree import DecisionTreeRegressor, DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier, GradientBoostingRegressor, GradientBoostingClassifier\n",
        "from sklearn.neighbors import KNeighborsRegressor, KNeighborsClassifier\n",
        "from sklearn.svm import SVR, SVC\n",
        "\n",
        "from sklearn.metrics import (mean_absolute_error, mean_squared_error, r2_score,\n",
        "                             accuracy_score, precision_score, recall_score,\n",
        "                             f1_score, confusion_matrix, classification_report,\n",
        "                             roc_auc_score, roc_curve, max_error, mean_absolute_percentage_error)\n",
        "\n",
        "from google.colab import drive\n",
        "pd.options.mode.copy_on_write = True"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LOAD DATA FROM GOOGLE DRIVE"
      ],
      "metadata": {
        "id": "ok1UbZMG5Bwc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Loading raw data from Gdrive location...\")\n",
        "file_id = \"1Iyr7zX8u0gKWKUWCSgZUpcvbTuYBmw1V\"\n",
        "url = f\"https://drive.google.com/uc?id={file_id}\"\n",
        "\n",
        "listings_raw = pd.read_csv(url)\n",
        "print(\"Raw Data Shape:\",listings_raw.shape)"
      ],
      "metadata": {
        "id": "ML5gnboD96C5",
        "outputId": "7844ff97-9b90-4839-d71d-1bce32f7821a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading raw data from Gdrive location...\n",
            "Raw Data Shape: (22684, 79)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# DATA WRANGLING"
      ],
      "metadata": {
        "id": "3f4Y7ESlezbo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## SHOW COLUMNS AND MANUALLY REMOVE UNWANTED (DOMAIN KNOWLEDGE)"
      ],
      "metadata": {
        "id": "TRCe8HyClssQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = listings_raw.copy()\n",
        "list(df)"
      ],
      "metadata": {
        "id": "egtjVcxHl261",
        "outputId": "6b92cb86-0b97-4bf2-ad41-74d54e116aba",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['id',\n",
              " 'listing_url',\n",
              " 'scrape_id',\n",
              " 'last_scraped',\n",
              " 'source',\n",
              " 'name',\n",
              " 'description',\n",
              " 'neighborhood_overview',\n",
              " 'picture_url',\n",
              " 'host_id',\n",
              " 'host_url',\n",
              " 'host_name',\n",
              " 'host_since',\n",
              " 'host_location',\n",
              " 'host_about',\n",
              " 'host_response_time',\n",
              " 'host_response_rate',\n",
              " 'host_acceptance_rate',\n",
              " 'host_is_superhost',\n",
              " 'host_thumbnail_url',\n",
              " 'host_picture_url',\n",
              " 'host_neighbourhood',\n",
              " 'host_listings_count',\n",
              " 'host_total_listings_count',\n",
              " 'host_verifications',\n",
              " 'host_has_profile_pic',\n",
              " 'host_identity_verified',\n",
              " 'neighbourhood',\n",
              " 'neighbourhood_cleansed',\n",
              " 'neighbourhood_group_cleansed',\n",
              " 'latitude',\n",
              " 'longitude',\n",
              " 'property_type',\n",
              " 'room_type',\n",
              " 'accommodates',\n",
              " 'bathrooms',\n",
              " 'bathrooms_text',\n",
              " 'bedrooms',\n",
              " 'beds',\n",
              " 'amenities',\n",
              " 'price',\n",
              " 'minimum_nights',\n",
              " 'maximum_nights',\n",
              " 'minimum_minimum_nights',\n",
              " 'maximum_minimum_nights',\n",
              " 'minimum_maximum_nights',\n",
              " 'maximum_maximum_nights',\n",
              " 'minimum_nights_avg_ntm',\n",
              " 'maximum_nights_avg_ntm',\n",
              " 'calendar_updated',\n",
              " 'has_availability',\n",
              " 'availability_30',\n",
              " 'availability_60',\n",
              " 'availability_90',\n",
              " 'availability_365',\n",
              " 'calendar_last_scraped',\n",
              " 'number_of_reviews',\n",
              " 'number_of_reviews_ltm',\n",
              " 'number_of_reviews_l30d',\n",
              " 'availability_eoy',\n",
              " 'number_of_reviews_ly',\n",
              " 'estimated_occupancy_l365d',\n",
              " 'estimated_revenue_l365d',\n",
              " 'first_review',\n",
              " 'last_review',\n",
              " 'review_scores_rating',\n",
              " 'review_scores_accuracy',\n",
              " 'review_scores_cleanliness',\n",
              " 'review_scores_checkin',\n",
              " 'review_scores_communication',\n",
              " 'review_scores_location',\n",
              " 'review_scores_value',\n",
              " 'license',\n",
              " 'instant_bookable',\n",
              " 'calculated_host_listings_count',\n",
              " 'calculated_host_listings_count_entire_homes',\n",
              " 'calculated_host_listings_count_private_rooms',\n",
              " 'calculated_host_listings_count_shared_rooms',\n",
              " 'reviews_per_month']"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check size of data frame before drops\n",
        "print(\"Before column drops:\",df.shape)"
      ],
      "metadata": {
        "id": "gjqSpUfcmYdn",
        "outputId": "6cfe370f-f194-4ca6-d37d-8c362e71a522",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Before column drops: (22684, 79)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# The following columns are irrelevant, and thus, we have chosen to drop them.\n",
        "df = df.drop(columns=[\"id\",\"listing_url\",\"scrape_id\",\"source\",\"host_id\",\"host_url\",\"calendar_last_scraped\",\"first_review\",\"host_neighbourhood\"])\n",
        "\n",
        "# The following columns could impact a listing's \"success\" (discrimination, etc.), but due to the complexity and the scope of this project,\n",
        "# we have chosen to drop it.\n",
        "df = df.drop(columns=[\"name\",\"picture_url\",\"host_name\",\"host_thumbnail_url\",\"host_picture_url\"])\n",
        "\n",
        "# Dropping the following columns in favor of \"calculated_host_listings_count,\" because that is the direct calculation of how many listings\n",
        "# a host has at the time of scrape. The metadata also notes that this calculation is \"unknown,\" and thereby less trustworthy.\n",
        "df = df.drop(columns=[\"host_listings_count\",\"host_total_listings_count\"])\n",
        "\n",
        "# Dropping in favor of \"host_identitity_verified,\" which is a boolean that indicates whether or not the host is verified.\n",
        "df = df.drop(columns=[\"host_verifications\"])\n",
        "\n",
        "# Dropping in favor of \"neighborhood_cleansed.\"\n",
        "df = df.drop(columns=[\"neighbourhood\"])\n",
        "\n",
        "# Dropping the following, as they are completely empty attributes.\n",
        "df = df.drop(columns=[\"neighbourhood_group_cleansed\",\"calendar_updated\",\"license\"])\n",
        "\n",
        "# Dropping the following columns in favor of \"mini_nights\" and \"maximum_nights.\"\n",
        "df = df.drop(columns=[\"minimum_minimum_nights\",\"maximum_minimum_nights\",\"minimum_maximum_nights\",\"maximum_maximum_nights\",\"minimum_nights_avg_ntm\",\"maximum_nights_avg_ntm\"])\n",
        "\n",
        "# Dropping the following columns, because there is no information about they represent.\n",
        "df = df.drop(columns=[\"has_availability\",\"availability_eoy\"])\n",
        "\n",
        "''' Dropping the following columns, because we have selected \"availability_30\" as our target variable. We believe this the most accurate\n",
        "indicator of a listing's popularity/success, because listings will on average be booked more in the short term than in the long term.\n",
        "We would be able to attribute the availability to an actual \"interest level,\" rather than a lack of booking simply due to time considerations.\n",
        "Seasonality should not matter since the scope of our listings is limited to Copenhagen, so theoretically, all listings would be impacted equally\n",
        "by seasonality. '''\n",
        "df = df.drop(columns=[\"availability_60\",\"availability_90\",\"availability_365\"])\n",
        "\n",
        "# Dropping the following columns in favor \"number_of_reviews\" for simplicity.\n",
        "df = df.drop(columns=[\"number_of_reviews_ltm\",\"number_of_reviews_l30d\"])\n",
        "\n",
        "# Dropping in favor \"number_of_reviews\" for simplicity.\n",
        "df = df.drop(columns=[\"number_of_reviews_ly\"])\n",
        "\n",
        "# Irrelevant and would introduce data leakage.\n",
        "df = df.drop(columns=[\"estimated_revenue_l365d\"])\n",
        "\n",
        "# Dropping the following attributes because they will not be available at the time of prediction.\n",
        "df = df.drop(columns=[\"review_scores_rating\",\"review_scores_accuracy\",\"review_scores_cleanliness\",\"review_scores_checkin\",\"review_scores_communication\",\"review_scores_location\",\"review_scores_value\"])\n",
        "\n",
        "# Dropping the following columns in favor of \"calculated_host_listings_count\" for simplicity.\n",
        "df = df.drop(columns=[\"calculated_host_listings_count_entire_homes\",\"calculated_host_listings_count_private_rooms\",\"calculated_host_listings_count_shared_rooms\"])\n",
        "\n",
        "# Dropping in favor of \"number_of_reviews.\"\n",
        "df = df.drop(columns=[\"reviews_per_month\"])\n",
        "\n",
        "# Check size of data frame after drops\n",
        "print(\"After column drops:\",df.shape)\n"
      ],
      "metadata": {
        "id": "sNw1htS_mT7k",
        "outputId": "8eab1eb0-d65f-4cf1-e05f-484edc137546",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "After column drops: (22684, 32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## AUDIT THE DATA TO DETERMINE WHAT NEEDS TO BE CLEANSED"
      ],
      "metadata": {
        "id": "cNv_KmHRF5WV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a function that will audit the raw data and provide an overview, making it easier to systematically determine what needs to be cleansed.\n",
        "\n",
        "def audit_dataframe(df, name=\"DataFrame\"):\n",
        "    print(f\"\\n=== AIRBNB DATA AUDIT: {name} ===\")\n",
        "    print(f\"Shape: {df.shape[0]} rows × {df.shape[1]} columns\\n\")\n",
        "\n",
        "    # ----- SHOW NULL SUMMARY -----\n",
        "    print(\"---- Missing Values ----\")\n",
        "    nulls = df.isnull().sum()\n",
        "    nulls_percent = (df.isnull().mean() * 100).round(2)\n",
        "    null_summary = pd.DataFrame({\n",
        "        \"null_count\": nulls,\n",
        "        \"null_percent\": nulls_percent,\n",
        "        \"dtype\": df.dtypes\n",
        "    })\n",
        "    print(null_summary[nulls > 0].sort_values(\"null_percent\", ascending=False))\n",
        "    print(\"\\n\")\n",
        "\n",
        "    # ----- SHOW DATA TYPES -----\n",
        "    print(\"---- Data Types ----\")\n",
        "    with pd.option_context(\"display.max_rows\", None, \"display.max_columns\", None):\n",
        "      print(df.dtypes)\n",
        "    print(\"\\n\")\n",
        "\n",
        "    # ----- SHOW DESCRIPTIVE STATS -----\n",
        "    print(\"---- Descriptive Statistics (Numerical) ----\")\n",
        "    print(df.describe(include=[np.number]).transpose())\n",
        "    print(\"\\n\")\n",
        "\n",
        "    print(\"---- Descriptive Statistics (Categorical) ----\")\n",
        "    print(df.describe(include=['object', 'category']).transpose())\n",
        "    print(\"\\n\")\n",
        "\n",
        "    # ----- SHOW UNIQUE VALUES -----\n",
        "    print(\"---- Unique Value Counts ----\")\n",
        "    unique_counts = df.nunique().sort_values()\n",
        "    print(unique_counts)\n",
        "    print(\"\\n\")\n",
        "\n",
        "    # ----- SHOW SAMPLE VALUES FOR EACH COLUMN -----\n",
        "    print(\"---- Sample Values ----\")\n",
        "    for col in df.columns:\n",
        "        print(f\"{col}: {df[col].dropna().unique()[:5]} ...\")\n",
        "    print(\"\\n\")\n",
        "\n",
        "    # ----- SHOW BOOLEAN DISTRIBUTION -----\n",
        "    bool_cols = df.select_dtypes(include=\"bool\").columns\n",
        "    if len(bool_cols) > 0:\n",
        "        print(\"---- Boolean Column Distributions ----\")\n",
        "        for col in bool_cols:\n",
        "            print(f\"{col}:\\n{df[col].value_counts()}\")\n",
        "            print(\"\")\n",
        "    print(\"\\n\")\n",
        "\n",
        "    # ----- SHOW CATEGORICAL CARDINALITY -----\n",
        "    print(\"---- Categorical Cardinality ----\")\n",
        "    cat_cols = df.select_dtypes(include=[\"object\", \"category\"]).columns\n",
        "    for col in cat_cols:\n",
        "        print(f\"{col}: {df[col].nunique()} unique values\")\n",
        "    print(\"\\n\")\n",
        "\n",
        "    # ----- SHOW DUPLICATES -----\n",
        "    print(\"---- Duplicate Rows ----\")\n",
        "    dupes = df.duplicated().sum()\n",
        "    print(f\"Duplicate rows: {dupes}\")\n",
        "    print(\"\\n\")\n",
        "\n",
        "    print(\"=== END AUDIT ===\\n\")\n"
      ],
      "metadata": {
        "id": "rq3CDvgbhvii"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "audit_dataframe(df, name=\"Airbnb Raw Data\")"
      ],
      "metadata": {
        "id": "zC36zrlUivVg",
        "outputId": "6622b8ff-b89f-4238-fecc-36423bd591fc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== AIRBNB DATA AUDIT: Airbnb Raw Data ===\n",
            "Shape: 22684 rows × 32 columns\n",
            "\n",
            "---- Missing Values ----\n",
            "                        null_count  null_percent    dtype\n",
            "neighborhood_overview        14459         63.74   object\n",
            "host_about                   13381         58.99   object\n",
            "bathrooms                     8858         39.05  float64\n",
            "beds                          8856         39.04  float64\n",
            "price                         8853         39.03   object\n",
            "host_response_time            7853         34.62   object\n",
            "host_response_rate            7853         34.62   object\n",
            "host_acceptance_rate          5288         23.31   object\n",
            "host_location                 4082         18.00   object\n",
            "last_review                   3146         13.87   object\n",
            "bedrooms                       716          3.16  float64\n",
            "description                    614          2.71   object\n",
            "host_since                     529          2.33   object\n",
            "host_identity_verified         529          2.33   object\n",
            "host_has_profile_pic           529          2.33   object\n",
            "host_is_superhost              238          1.05   object\n",
            "bathrooms_text                   8          0.04   object\n",
            "\n",
            "\n",
            "---- Data Types ----\n",
            "last_scraped                       object\n",
            "description                        object\n",
            "neighborhood_overview              object\n",
            "host_since                         object\n",
            "host_location                      object\n",
            "host_about                         object\n",
            "host_response_time                 object\n",
            "host_response_rate                 object\n",
            "host_acceptance_rate               object\n",
            "host_is_superhost                  object\n",
            "host_has_profile_pic               object\n",
            "host_identity_verified             object\n",
            "neighbourhood_cleansed             object\n",
            "latitude                          float64\n",
            "longitude                         float64\n",
            "property_type                      object\n",
            "room_type                          object\n",
            "accommodates                        int64\n",
            "bathrooms                         float64\n",
            "bathrooms_text                     object\n",
            "bedrooms                          float64\n",
            "beds                              float64\n",
            "amenities                          object\n",
            "price                              object\n",
            "minimum_nights                      int64\n",
            "maximum_nights                      int64\n",
            "availability_30                     int64\n",
            "number_of_reviews                   int64\n",
            "estimated_occupancy_l365d           int64\n",
            "last_review                        object\n",
            "instant_bookable                   object\n",
            "calculated_host_listings_count      int64\n",
            "dtype: object\n",
            "\n",
            "\n",
            "---- Descriptive Statistics (Numerical) ----\n",
            "                                  count        mean         std       min  \\\n",
            "latitude                        22684.0   55.680435    0.019021  55.61566   \n",
            "longitude                       22684.0   12.558520    0.031238  12.45400   \n",
            "accommodates                    22684.0    3.327191    1.641362   1.00000   \n",
            "bathrooms                       13826.0    1.102090    0.337810   0.00000   \n",
            "bedrooms                        21968.0    1.616078    0.893470   0.00000   \n",
            "beds                            13828.0    1.866141    1.271868   0.00000   \n",
            "minimum_nights                  22684.0    4.641950   17.782766   1.00000   \n",
            "maximum_nights                  22684.0  305.541792  376.742573   1.00000   \n",
            "availability_30                 22684.0    6.135514    8.673801   0.00000   \n",
            "number_of_reviews               22684.0   18.932507   45.940124   0.00000   \n",
            "estimated_occupancy_l365d       22684.0   31.659848   49.882944   0.00000   \n",
            "calculated_host_listings_count  22684.0    4.871451   26.867545   1.00000   \n",
            "\n",
            "                                      25%        50%         75%         max  \n",
            "latitude                        55.666253  55.681744   55.695720    55.73247  \n",
            "longitude                       12.540608  12.555033   12.580485    12.63972  \n",
            "accommodates                     2.000000   3.000000    4.000000    16.00000  \n",
            "bathrooms                        1.000000   1.000000    1.000000     8.00000  \n",
            "bedrooms                         1.000000   1.000000    2.000000     9.00000  \n",
            "beds                             1.000000   1.000000    2.000000    16.00000  \n",
            "minimum_nights                   2.000000   3.000000    4.000000  1111.00000  \n",
            "maximum_nights                  20.000000  90.000000  365.000000  1125.00000  \n",
            "availability_30                  0.000000   1.000000    9.000000    30.00000  \n",
            "number_of_reviews                2.000000   7.000000   19.000000  2366.00000  \n",
            "estimated_occupancy_l365d        0.000000  12.000000   40.000000   255.00000  \n",
            "calculated_host_listings_count   1.000000   1.000000    1.000000   247.00000  \n",
            "\n",
            "\n",
            "---- Descriptive Statistics (Categorical) ----\n",
            "                        count unique  \\\n",
            "last_scraped            22684      6   \n",
            "description             22070  21430   \n",
            "neighborhood_overview    8225   7901   \n",
            "host_since              22155   4729   \n",
            "host_location           18602    333   \n",
            "host_about               9303   7736   \n",
            "host_response_time      14831      4   \n",
            "host_response_rate      14831     91   \n",
            "host_acceptance_rate    17396    101   \n",
            "host_is_superhost       22446      2   \n",
            "host_has_profile_pic    22155      2   \n",
            "host_identity_verified  22155      2   \n",
            "neighbourhood_cleansed  22684     11   \n",
            "property_type           22684     55   \n",
            "room_type               22684      4   \n",
            "bathrooms_text          22676     21   \n",
            "amenities               22684  21560   \n",
            "price                   13831   2496   \n",
            "last_review             19538   1742   \n",
            "instant_bookable        22684      2   \n",
            "\n",
            "                                                                      top  \\\n",
            "last_scraped                                                   2025-07-01   \n",
            "description             Your family will be close to everything when y...   \n",
            "neighborhood_overview   This area is known for its mix of restaurants ...   \n",
            "host_since                                                     2018-05-03   \n",
            "host_location                                         Copenhagen, Denmark   \n",
            "host_about              Vi udlejer møblerede lejligheder og har mere e...   \n",
            "host_response_time                                         within an hour   \n",
            "host_response_rate                                                   100%   \n",
            "host_acceptance_rate                                                 100%   \n",
            "host_is_superhost                                                       f   \n",
            "host_has_profile_pic                                                    t   \n",
            "host_identity_verified                                                  t   \n",
            "neighbourhood_cleansed                                            Nrrebro   \n",
            "property_type                                          Entire rental unit   \n",
            "room_type                                                 Entire home/apt   \n",
            "bathrooms_text                                                     1 bath   \n",
            "amenities               [\"TV\", \"Paid parking on premises\", \"Washer\", \"...   \n",
            "price                                                             $900.00   \n",
            "last_review                                                    2025-06-22   \n",
            "instant_bookable                                                        f   \n",
            "\n",
            "                         freq  \n",
            "last_scraped             6401  \n",
            "description                52  \n",
            "neighborhood_overview      11  \n",
            "host_since                251  \n",
            "host_location           15966  \n",
            "host_about                247  \n",
            "host_response_time       5742  \n",
            "host_response_rate      10528  \n",
            "host_acceptance_rate     4924  \n",
            "host_is_superhost       19672  \n",
            "host_has_profile_pic    21426  \n",
            "host_identity_verified  19641  \n",
            "neighbourhood_cleansed   4097  \n",
            "property_type           13038  \n",
            "room_type               20780  \n",
            "bathrooms_text          18162  \n",
            "amenities                  37  \n",
            "price                     336  \n",
            "last_review               817  \n",
            "instant_bookable        20502  \n",
            "\n",
            "\n",
            "---- Unique Value Counts ----\n",
            "host_has_profile_pic                  2\n",
            "host_identity_verified                2\n",
            "host_is_superhost                     2\n",
            "instant_bookable                      2\n",
            "room_type                             4\n",
            "host_response_time                    4\n",
            "last_scraped                          6\n",
            "bedrooms                             10\n",
            "bathrooms                            11\n",
            "neighbourhood_cleansed               11\n",
            "accommodates                         16\n",
            "beds                                 16\n",
            "bathrooms_text                       21\n",
            "calculated_host_listings_count       24\n",
            "availability_30                      31\n",
            "property_type                        55\n",
            "minimum_nights                       71\n",
            "host_response_rate                   91\n",
            "estimated_occupancy_l365d            94\n",
            "host_acceptance_rate                101\n",
            "maximum_nights                      175\n",
            "host_location                       333\n",
            "number_of_reviews                   336\n",
            "last_review                        1742\n",
            "price                              2496\n",
            "host_since                         4729\n",
            "host_about                         7736\n",
            "neighborhood_overview              7901\n",
            "latitude                          15397\n",
            "longitude                         17045\n",
            "description                       21430\n",
            "amenities                         21560\n",
            "dtype: int64\n",
            "\n",
            "\n",
            "---- Sample Values ----\n",
            "last_scraped: ['2025-06-30' '2025-07-01' '2025-06-28' '2025-06-27' '2025-06-29'] ...\n",
            "description: ['Welcome to our home, we hope you will enjoy Wonderful Copenhagen!<br /><br />Our penthouse apartment is very spacious with 164 m2 incl. a private rooftop terrasse where you can relax or grill. Despite the location in central Copenhagen, the street is very quiet and the neighbors are never heard.<br /><br />Most attractions are within walking distance, as are plenty of great restaurants in Vesterbro and \"Kødbyen\".  We are happy på guide you to our favourites :-). Trains and Metro are also a few minutes away by foot.'\n",
            " 'You enter a narrow entrance and feel the good mood right away. The bright rooms welcome you into the large living room with the sofa furnished in bay window. 2 modern bathroom with heating in the floor you will find at each end of the apartment where you also have two large bedroom. Furthermore, a good dining kitchen with cozy details and space for a small dining table. Last a slightly larger room which here is furnished with dining table in lounge atmosphere for several. 155m2'\n",
            " 'Our flat is placed in a Central AND Quiet neighborhood. 3 stops on the train from the heart of Copenhagen and only a 5 minute walk from the biggest park in Copenhagen; Fælledparken!'\n",
            " \"It doesn't get more central than this. Historical sites, castles, shopping, transportation, dining and parks at your door step. Yet no traffic noise. Large flat in historical building with lots of antique quaint features and upcycled carpenter work.  If you are into sleek new scandinavian style - this place is not for you. But if you like to take a bite of history and mystery, this is a perfect vacation home.\"\n",
            " 'Big, bright, airy and attractive apartment decorated in Scandinavian style.'] ...\n",
            "neighborhood_overview: ['What else is nearby?<br />To be honest, We think our neighbourhood \"Vesterbro\" is the coolest in Copenhagen. Just 100 meters away you have Sdr. Boulevard, which is a lovely open boulevard, where lots of the cool kids hang out in the afternoon and evening. \"Kødbyen\" (The old meat packing district), which has now been made into trendy restaurents, bars and nightclubs, is only 350 meters away. If you feel more like authentic old bars, there are plenty nearby.. There are lots of parks and playgrounds in the neighborhood. The beautiful harbour is great for swimming and only 1 km away. You will be able to manage you days here on foot, but we also highly recommend biking around. Since 2015, Copenhagen has been ranked the world\\'s top cycling city several times. You can rent bikes at the end of the street.'\n",
            " \"Værnedamsvej area is super hip area, we call it little Paris. Saterday you'll find special cosy activities and super nice atmosphere. Meatdistrict just in the hood as well, please take a look. TIVOLI is plassed like it is in the bachgarden.\"\n",
            " \"Area: <br />This is the eye of Cph. right between the Botanical Gardens, the Kings Gardens and the pedestrian street shopping area. You will also find all the dining options, you would need right by. It is a 30 second walk from the indoor gourmet market place, grocery stores and  Nørreport Station and Metro, which is the main transportation hub in the city. Take the metro from the airport (there is only 1 line) and 15 minutes later, you are in your vacation home.<br />So kick back and feel at home, chill out in a park, shop till you drop or take a jog around the 'lakes' in copenhagen - 10 minute walk away.\"\n",
            " \"The flat is excellently located in Islands Brygge, a lovely and vibrant harbourfront area in central Copenhagen. The neighborhood is noted for its waterfront park which is one of the most popular areas along the Copenhagen harbourfront and the location of Copenhagen's most attractive harbour bath. <br />The neighborhood has a multitude of good cafes, restaurants and wine bars as well as supermarkets and small shops. There is also a large park (Amager Fælled) just 3 min. from the flat perfect for walking and cycling, and a 15 min. walk will take you to The City Hall Square (downtown).\"\n",
            " 'My neighborhood is called Vibekevang, and is a quiet pearl in the busy town of Copenhagen..Its located in the outskirts of Østerbro in walking distance (15-30 min depending on your walking speed), of central Nørrebro and central Østerbro..'] ...\n",
            "host_since: ['2010-05-15' '2010-05-22' '2010-06-07' '2010-06-10' '2010-05-11'] ...\n",
            "host_location: ['Copenhagen, Denmark' 'Frederiksberg, Denmark' 'Denmark'\n",
            " 'København, Denmark' 'Reykjavik, Iceland'] ...\n",
            "host_about: ['I have a Master of Arts in Musicology and I work as a vocal coach and a singer and I LOVE to travel and meet people from all over the world. \\nI live in lively Vesterbro with my 6 yr. old son Wili.'\n",
            " 'Hi and welcome. My name is Ebbe, I am a medical doctor working in Copenhagen. I live in the flat with my girlfriend Lea who is working as a nurse. We have two little girls: Nora is 6 years old and Luna is 2 years old.\\n\\nWe love sports, music and travelling, and we look forward welcoming you to Wonderful Copenhagen :-)'\n",
            " 'As profession - Set and Costumedesigner for Avangarde Theatre, Modern Dance and Performance. A traveler, enjoy to se the whole world, meet people and talk about the world situation'\n",
            " \"Anders:\\r\\nHitchhiked 100.000 km's, Been publicly speaking more than 500 times, Traveled 80 countries, Lived 36 yrs. Have 7 sisters and brothers, Twins, 1 wife... and a million plans!\\r\\nMaria:\\r\\nSinger/nurse/Twin-Mum/training to be a midwife. Lived 6 years in London and toured the world with a British Pop band…including an appearance at the Bollywood Awards:-)\"\n",
            " 'We are...\\nCarsten and Christina, and our 3 awesome kids. Carsten is a freelance photographer and Christina works in the NGO sector concerning refugees globally. Traveling is a passion we share, and airbnb has added greatly to the fantastic experiences we have had. \\nYou are...\\n...welcome to stay in our home whoever you are. As long as you take good care of it. We love our place,  and we hope you will too.'] ...\n",
            "host_response_time: ['within a few hours' 'within an hour' 'within a day' 'a few days or more'] ...\n",
            "host_response_rate: ['100%' '50%' '71%' '83%' '90%'] ...\n",
            "host_acceptance_rate: ['50%' '100%' '63%' '88%' '83%'] ...\n",
            "host_is_superhost: ['f' 't'] ...\n",
            "host_has_profile_pic: ['t' 'f'] ...\n",
            "host_identity_verified: ['t' 'f'] ...\n",
            "neighbourhood_cleansed: ['Vesterbro-Kongens Enghave' 'sterbro' 'Indre By' 'Amager Vest' 'Nrrebro'] ...\n",
            "latitude: [55.67023    55.6666017  55.672638   55.71176    55.68428802] ...\n",
            "longitude: [12.55504    12.5552831  12.552493   12.57091    12.57301903] ...\n",
            "property_type: ['Entire rental unit' 'Entire condo' 'Private room in condo'\n",
            " 'Private room in rental unit' 'Entire loft'] ...\n",
            "room_type: ['Entire home/apt' 'Private room' 'Shared room' 'Hotel room'] ...\n",
            "accommodates: [2 6 4 1 5] ...\n",
            "bathrooms: [1.  2.  0.5 1.5 0. ] ...\n",
            "bathrooms_text: ['1 bath' '1.5 baths' '2 baths' '1 shared bath' 'Half-bath'] ...\n",
            "bedrooms: [1. 4. 2. 3. 5.] ...\n",
            "beds: [1. 3. 2. 4. 6.] ...\n",
            "amenities: ['[\"Backyard\", \"Dining table\", \"Essentials\", \"Patio or balcony\", \"Dishes and silverware\", \"Host greets you\", \"Room-darkening shades\", \"Refrigerator\", \"Dishwasher\", \"Hair dryer\", \"Oven\", \"Wine glasses\", \"Heating\", \"Toaster\", \"Pack \\\\u2019n play/Travel crib\", \"Washer\", \"Children\\\\u2019s books and toys\", \"Hangers\", \"Kitchen\", \"Stove\", \"Blender\", \"Paid parking off premises\", \"Baby bath\", \"Coffee maker: Nespresso\", \"Cooking basics\", \"Microwave\", \"Children\\\\u2019s dinnerware\", \"Hot water\", \"Wifi\"]'\n",
            " '[\"Coffee maker: drip coffee maker, espresso machine, french press, Nespresso\", \"Shared backyard\", \"Dryer \\\\u2013\\\\u00a0In unit\", \"Private BBQ grill: gas\", \"Essentials\", \"Sound system\", \"Dishes and silverware\", \"Standalone high chair - always at the listing\", \"Conditioner\", \"Drying rack for clothing\", \"Refrigerator\", \"Dishwasher\", \"Hair dryer\", \"Children\\\\u2019s books and toys for ages 2-5 years old and 5-10 years old\", \"Oven\", \"Wine glasses\", \"Private entrance\", \"EV charger\", \"Heating\", \"Washer \\\\u2013\\\\u00a0In unit\", \"Bed linens\", \"Toaster\", \"Outdoor dining area\", \"Window guards\", \"Changing table\", \"Smoke alarm\", \"Hot water kettle\", \"TV with standard cable\", \"Coffee\", \"Shared beach access\", \"Paid street parking off premises\", \"Hangers\", \"Indoor fireplace: wood-burning\", \"Barbecue utensils\", \"Laundromat nearby\", \"Private patio or balcony\", \"Courtyard view\", \"Kitchen\", \"Children\\\\u2019s dinnerware\", \"Stove\", \"Outdoor furniture\", \"Baking sheet\", \"Blender\", \"Baby bath\", \"City skyline view\", \"Cleaning products\", \"Cooking basics\", \"Freezer\", \"Clothing storage: closet\", \"Microwave\", \"Body soap\", \"Hot water\", \"Wifi\"]'\n",
            " '[\"Dedicated workspace\", \"Hot water\", \"Iron\", \"Carbon monoxide alarm\", \"Room-darkening shades\", \"Private hot tub\", \"Hair dryer\", \"Shampoo\", \"Outdoor furniture\", \"Hot water kettle\", \"Stove\", \"Lockbox\", \"Heating\", \"Kitchen\", \"Cleaning products\", \"Children\\\\u2019s books and toys\", \"Portable fans\", \"Shower gel\", \"Oven\", \"Refrigerator\", \"First aid kit\", \"Wifi\", \"Shared backyard \\\\u2013 Not fully fenced\", \"Essentials\", \"Hangers\", \"Bed linens\", \"Toaster\", \"Paid parking off premises\", \"Cooking basics\", \"Dining table\", \"Washer\", \"Drying rack for clothing\", \"Self check-in\", \"Dishwasher\", \"Wine glasses\", \"Microwave\", \"Dishes and silverware\", \"Courtyard view\", \"Host greets you\", \"Bathtub\", \"Smoke alarm\", \"TV with Chromecast\", \"Dryer\"]'\n",
            " '[\"Backyard\", \"Free parking on premises\", \"Essentials\", \"Fire extinguisher\", \"Iron\", \"TV with standard cable\", \"Smoke alarm\", \"Heating\", \"Kitchen\", \"Wifi\"]'\n",
            " '[\"Dedicated workspace\", \"Dining table\", \"Lockbox\", \"Essentials\", \"Dishes and silverware\", \"Host greets you\", \"Record player\", \"Drying rack for clothing\", \"Refrigerator\", \"Free dryer \\\\u2013 In unit\", \"Dishwasher\", \"Hair dryer\", \"Free washer \\\\u2013 In unit\", \"Coffee maker: french press, Nespresso\", \"Oven\", \"Wine glasses\", \"Private entrance\", \"Heating\", \"Induction stove\", \"Bed linens\", \"Toaster\", \"Iron\", \"Shared beach access\", \"Hangers\", \"Kitchen\", \"Books and reading material\", \"42 inch TV with Netflix, Disney+, Apple TV\", \"Long term stays allowed\", \"Self check-in\", \"Cleaning products\", \"Cooking basics\", \"Freezer\", \"Clothing storage: closet\", \"Microwave\", \"Hot water\", \"Wifi\"]'] ...\n",
            "price: ['$900.00' '$2,282.00' '$589.00' '$2,223.00' '$1,760.00'] ...\n",
            "minimum_nights: [  7   3 100   5   2] ...\n",
            "maximum_nights: [  14   10    5 1125   70] ...\n",
            "availability_30: [6 0 4 3 5] ...\n",
            "number_of_reviews: [27 19 85  7 37] ...\n",
            "estimated_occupancy_l365d: [  0  18 130 120  60] ...\n",
            "last_review: ['2024-03-31' '2022-08-22' '2025-06-21' '2016-09-15' '2025-06-22'] ...\n",
            "instant_bookable: ['f' 't'] ...\n",
            "calculated_host_listings_count: [1 2 7 3 4] ...\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "---- Categorical Cardinality ----\n",
            "last_scraped: 6 unique values\n",
            "description: 21430 unique values\n",
            "neighborhood_overview: 7901 unique values\n",
            "host_since: 4729 unique values\n",
            "host_location: 333 unique values\n",
            "host_about: 7736 unique values\n",
            "host_response_time: 4 unique values\n",
            "host_response_rate: 91 unique values\n",
            "host_acceptance_rate: 101 unique values\n",
            "host_is_superhost: 2 unique values\n",
            "host_has_profile_pic: 2 unique values\n",
            "host_identity_verified: 2 unique values\n",
            "neighbourhood_cleansed: 11 unique values\n",
            "property_type: 55 unique values\n",
            "room_type: 4 unique values\n",
            "bathrooms_text: 21 unique values\n",
            "amenities: 21560 unique values\n",
            "price: 2496 unique values\n",
            "last_review: 1742 unique values\n",
            "instant_bookable: 2 unique values\n",
            "\n",
            "\n",
            "---- Duplicate Rows ----\n",
            "Duplicate rows: 0\n",
            "\n",
            "\n",
            "=== END AUDIT ===\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## FILTER THE DATASET TO REMOVE LISTINGS WITHOUT REVIEWS AND WITH NO OCCUPANCY IN THE LAST YEAR"
      ],
      "metadata": {
        "id": "4zN4rqJMcYpl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''We have chosen to remove listings without reviews in 2025 and no occupancy in the last year. We have chosen to filter \"last_review\" for\n",
        "listings that have a review within 6 months of the scrape date and \"estimated_occupancy_l365d\" for listings that have a non-zero value. We have\n",
        "done this to ensure we are including only listings that are active, and thereby more informative for our model.\n",
        "\n",
        "We recognize that this approach may introduce selection bias, since the remaining dataset over-represents highly active, consistently booked listings.\n",
        "As a result, our model will be trained only on relatively \"successful\" or \"popular\" listings and may systematically overestimate occupancy for\n",
        "lower-activity or newly listed properties. In other words, the predictions may not generalize as well to the full population of Airbnb listings,\n",
        "because the model never sees ultra low-engagement listings.'''\n",
        "\n",
        "df = df.query(\n",
        "    \"last_review >= '2025-01-01' and estimated_occupancy_l365d > 0\"\n",
        ")"
      ],
      "metadata": {
        "id": "7oyzHoag71Fw"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check sizes of data and filtered data\n",
        "print(\"Row count before filtering:\", len(listings_raw))\n",
        "print(\"Row count after filtering:\", len(df))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4nzRHrvQavYQ",
        "outputId": "f0bcf9dd-8d14-49d8-e186-99005ee81a63"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Row count before filtering: 22684\n",
            "Row count after filtering: 10132\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# We are now dropping the aforementioned columns, as they are no longer needed post-filtering.\n",
        "\n",
        "df = df.drop(columns=[\"last_review\",\"estimated_occupancy_l365d\"])"
      ],
      "metadata": {
        "id": "jLx-A4fHoIQ0"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## CLEAN UP \"price\" ATTRIBUTE\n",
        "\n"
      ],
      "metadata": {
        "id": "vcwLLq8kS9qv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove $, commas, and spaces, then convert to numeric\n",
        "price_clean = (\n",
        "    df[\"price\"]\n",
        "    .astype(str)                             # handle existing ints / NA\n",
        "    .str.replace(r'[\\$,]', '', regex=True)   # remove $ and commas\n",
        "    .str.strip()\n",
        ")\n",
        "\n",
        "# Convert to numeric, coercing bad values (like '<NA>') to NaN\n",
        "price_numeric = pd.to_numeric(price_clean, errors=\"coerce\")\n",
        "\n",
        "# Store back as nullable integer\n",
        "df[\"price\"] = price_numeric.astype(\"Int64\")"
      ],
      "metadata": {
        "id": "OKGnV3WfS_HV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## VALIDATE PRICE ATTRIBUTE"
      ],
      "metadata": {
        "id": "Iyi71gAMMQIn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df[\"price\"].describe()"
      ],
      "metadata": {
        "id": "WX04EAYhMUnm",
        "outputId": "5183e013-652b-43f7-d8f2-eaa6e05967ad",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 335
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "count        7872.0\n",
              "mean     1374.50216\n",
              "std      1167.65617\n",
              "min           202.0\n",
              "25%           881.0\n",
              "50%          1168.0\n",
              "75%          1600.0\n",
              "max         63418.0\n",
              "Name: price, dtype: Float64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>price</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>7872.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>1374.50216</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>1167.65617</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>202.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>881.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>1168.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>1600.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>63418.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> Float64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 234
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## CREATE TWO DATAFRAMES WITH DIFFERENT \"price\" APPROACHES"
      ],
      "metadata": {
        "id": "0YnmQHfpXdT-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create two new dataframes to split between approaches (dropping missing prices vs. imputing missing prices)\n",
        "df_price_imputation = df.copy()\n",
        "df_drop_price = df.copy()\n",
        "\n",
        "median_price = df[\"price\"].median()\n",
        "df_price_imputation[\"price\"] = df_price_imputation[\"price\"].fillna(median_price).astype(\"Int64\")\n",
        "df_drop_price = df_drop_price.dropna(subset=[\"price\"])\n",
        "\n",
        "print(\"Shape of df with price imputation:\", df_price_imputation.shape)\n",
        "print(\"Shape of df with dropped blank prices:\", df_drop_price.shape)"
      ],
      "metadata": {
        "id": "hL6prWx2-z8f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7de95c70-6d92-47bd-c9ce-54c37c4ac7d1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of df with price imputation: (10132, 30)\n",
            "Shape of df with dropped blank prices: (7872, 30)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a dictionary with the two split datasets.\n",
        "# Instead of rewriting the pipeline for each version, we can loop over the dataset dictionary and train/evaluate all models on all variants cleanly.\n",
        "\n",
        "datasets = {\n",
        "    \"drop_missing_prices\": df_drop_price,\n",
        "    \"impute_price\": df_price_imputation\n",
        "}\n",
        "\n",
        "print(type(datasets))\n",
        "for name, df in datasets.items():\n",
        "    print(name, type(df))"
      ],
      "metadata": {
        "id": "54vjBoC3dL1M",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "41396934-b21e-40ea-cc7e-8f695d1c8aab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'dict'>\n",
            "drop_missing_prices <class 'pandas.core.frame.DataFrame'>\n",
            "impute_price <class 'pandas.core.frame.DataFrame'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## CLEAN UP BOOLEAN COLUMNS"
      ],
      "metadata": {
        "id": "Zki9UNYxXw7z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Some cols have boolean values \"f\" and \"t\", we change to 0 or 1\n",
        "bool_cols = [\n",
        "    \"host_is_superhost\",\n",
        "    \"host_has_profile_pic\",\n",
        "    \"host_identity_verified\",\n",
        "    \"instant_bookable\"\n",
        "]\n",
        "\n",
        "bool_map = {\n",
        "    \"t\": 1,\n",
        "    \"f\": 0,\n",
        "    \"true\": 1,\n",
        "    \"false\": 0,\n",
        "    True: 1,\n",
        "    False: 0,\n",
        "}\n",
        "\n",
        "# Fix boolean values in the datasets\n",
        "for name, df in datasets.items():\n",
        "  for col in bool_cols:\n",
        "      df[col] = (df[col].map(bool_map).astype(\"Int64\"))\n",
        "\n",
        "# Fill missing superhost values with 0 in the datasets\n",
        "for name, df in datasets.items():\n",
        "  df[\"host_is_superhost\"] = df[\"host_is_superhost\"].fillna(0).astype(\"Int64\")\n",
        "\n",
        "# Print results\n",
        "for name, df in datasets.items():\n",
        "  print(f\"Cleaned up column information for {name} dataframe...\\n\")\n",
        "  for col in bool_cols:\n",
        "    print(f\"{col} unique values:\", df[col].unique(),\"\\n\")"
      ],
      "metadata": {
        "id": "aHr-MFgzX3cL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d8949f38-0c9c-4886-841c-d8e36d494456"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cleaned up column information for drop_missing_prices dataframe...\n",
            "\n",
            "host_is_superhost unique values: <IntegerArray>\n",
            "[1, 0]\n",
            "Length: 2, dtype: Int64 \n",
            "\n",
            "host_has_profile_pic unique values: <IntegerArray>\n",
            "[1, <NA>, 0]\n",
            "Length: 3, dtype: Int64 \n",
            "\n",
            "host_identity_verified unique values: <IntegerArray>\n",
            "[1, 0, <NA>]\n",
            "Length: 3, dtype: Int64 \n",
            "\n",
            "instant_bookable unique values: <IntegerArray>\n",
            "[0, 1]\n",
            "Length: 2, dtype: Int64 \n",
            "\n",
            "Cleaned up column information for impute_price dataframe...\n",
            "\n",
            "host_is_superhost unique values: <IntegerArray>\n",
            "[1, 0]\n",
            "Length: 2, dtype: Int64 \n",
            "\n",
            "host_has_profile_pic unique values: <IntegerArray>\n",
            "[1, <NA>, 0]\n",
            "Length: 3, dtype: Int64 \n",
            "\n",
            "host_identity_verified unique values: <IntegerArray>\n",
            "[1, 0, <NA>]\n",
            "Length: 3, dtype: Int64 \n",
            "\n",
            "instant_bookable unique values: <IntegerArray>\n",
            "[0, 1]\n",
            "Length: 2, dtype: Int64 \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# We can see based on the information below, that a number of listings have a missing verification status and profile picture.\n",
        "for name, df in datasets.items():\n",
        "  print(f\"{name} results:\")\n",
        "  print(df[[\"host_has_profile_pic\",\"host_identity_verified\"]].isna().sum(),\"\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jMhHzjpOfVZ7",
        "outputId": "54aa9b51-99ce-412c-e05f-e5a9b0b3f396"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "drop_missing_prices results:\n",
            "host_has_profile_pic      236\n",
            "host_identity_verified    236\n",
            "dtype: int64 \n",
            "\n",
            "impute_price results:\n",
            "host_has_profile_pic      257\n",
            "host_identity_verified    257\n",
            "dtype: int64 \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Given the relatively small number of null rows, we have chosen to drop them rather than impute values.\n",
        "\n",
        "subset_cols = [\"host_has_profile_pic\", \"host_identity_verified\"]\n",
        "\n",
        "for name, df in datasets.items():\n",
        "    # Drop rows with NA in any of the subset columns\n",
        "    df.dropna(subset=subset_cols, inplace=True)\n",
        "\n",
        "    # Show remaining NA counts for those columns\n",
        "    print(f\"{name} results:\")\n",
        "    print(df[subset_cols].isna().sum(),\"\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oF6zZDFJYPyl",
        "outputId": "7c2e24d6-d817-418c-f87a-286c58ccb88a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "drop_missing_prices results:\n",
            "host_has_profile_pic      0\n",
            "host_identity_verified    0\n",
            "dtype: int64 \n",
            "\n",
            "impute_price results:\n",
            "host_has_profile_pic      0\n",
            "host_identity_verified    0\n",
            "dtype: int64 \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## CLEAN UP MISSING \"bed\" AND \"bedroom\" ATTRIBUTES"
      ],
      "metadata": {
        "id": "p3qS5NsS79xh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "''' There are three measures for how many people a property fits:\n",
        "1. \"accommodates\" = max number of guests\n",
        "2. \"bedrooms\" = number of bedrooms\n",
        "3. \"beds\" = number of beds '''\n",
        "\n",
        "for name, df in datasets.items():\n",
        "  print(f\"{name} results:\\n\",df[['accommodates','bedrooms','beds']].isna().sum(),\"\\n\")\n",
        "\n",
        "# \"accommodates\" has no missingness, while the others do, so we use combinations of them to impute values\n",
        "# We will use all for the training\n",
        "\n",
        "# THIS RESULT COULD INDICATE A PATTERN OF MISSINGNESS, SINCE ROWS WITH MISSING PRICES ALSO HAVE OTHER MISSING ATTRIBUTES.\n",
        "# WE COULD CHECK IF THERE IS MISSINGNESS ACROSS, FOR EXAMPLE, A CERTAIN TYPE OF LISTING, THEN THE RESULTS WILL BE SKEWED."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K3HKQpHT7-Tc",
        "outputId": "50952e92-9520-488c-fdab-cdc578adf9d1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "drop_missing_prices results:\n",
            " accommodates    0\n",
            "bedrooms        1\n",
            "beds            1\n",
            "dtype: int64 \n",
            "\n",
            "impute_price results:\n",
            " accommodates       0\n",
            "bedrooms         158\n",
            "beds            2240\n",
            "dtype: int64 \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# WE ARE DOING THE FOLLOWING ONLY ON THE PRICE IMPUTATION DF, SINCE THE DROP PRICE DF HAS ONLY 1 NULL VALUE.\n",
        "# Only use rows where all three variables are valid (non-missing, non-zero)\n",
        "valid = df_price_imputation[\n",
        "    (df_price_imputation['accommodates'] > 0) &\n",
        "    (df_price_imputation['beds'] > 0) &\n",
        "    (df_price_imputation['bedrooms'] > 0)\n",
        "]\n",
        "\n",
        "# Compute ratios\n",
        "valid['guests_per_bed'] = valid['accommodates'] / valid['beds']\n",
        "valid['beds_per_bedroom'] = valid['beds'] / valid['bedrooms']\n",
        "valid['guests_per_bedroom'] = valid['accommodates'] / valid['bedrooms']\n",
        "\n",
        "# Get averages and medians\n",
        "summary = valid[['guests_per_bed', 'beds_per_bedroom', 'guests_per_bedroom']].agg(['mean', 'median'])\n",
        "print(\"Statistics before imputation:\\n\", summary)\n",
        "\n",
        "# Use medians for integers\n",
        "guests_per_bed = summary.loc['median', 'guests_per_bed']\n",
        "beds_per_bedroom = summary.loc['median', 'beds_per_bedroom']\n",
        "guests_per_bedroom = summary.loc['median', 'guests_per_bedroom']\n",
        "\n",
        "# Impute median values where missing\n",
        "# For missing beds but nonmissing bedrooms, impute median beds per bedroom\n",
        "df_price_imputation.loc[df_price_imputation['beds'].isna() & df_price_imputation['bedrooms'].notna(), 'beds'] = df_price_imputation['bedrooms'] * beds_per_bedroom\n",
        "\n",
        "# For remaining missing beds, divide max guest count by median guests per bed\n",
        "df_price_imputation.loc[df_price_imputation['beds'].isna(), 'beds'] = df_price_imputation['accommodates'] / guests_per_bed\n",
        "\n",
        "# For missing bedrooms but nonmissing bedrooms, divide beds by beds per bedroom\n",
        "df_price_imputation.loc[df_price_imputation['bedrooms'].isna() & df_price_imputation['beds'].notna(), 'bedrooms'] = df_price_imputation['beds'] / beds_per_bedroom\n",
        "\n",
        "# For remaining missing bedrooms, divide max guest count by median guests per bedroom\n",
        "df_price_imputation.loc[df_price_imputation['bedrooms'].isna(), 'bedrooms'] = df_price_imputation['accommodates'] / guests_per_bedroom\n",
        "\n",
        "# Re-check missingness\n",
        "print(\"\\nRE-CHECKING MISSINGNESS ON PRICE IMPUTATION DATAFRAME:\\n\", df_price_imputation[['accommodates','bedrooms','beds']].isna().sum())\n",
        "\n",
        "# DROP THE 1 MISSING VALUE FOR THE DROP PRICE DATAFRAME\n",
        "df_drop_price = df_drop_price.dropna(subset=[\"beds\"])\n",
        "df_drop_price = df_drop_price.dropna(subset=[\"bedrooms\"])\n",
        "\n",
        "# Show the results\n",
        "print(\"\\nRE-CHECKING MISSINGNESS ON DROP PRICE DATAFRAME:\\n\", df_drop_price[['accommodates','bedrooms','beds']].isna().sum())\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_UxeNXHZ8COJ",
        "outputId": "ce57e0ae-25e0-47ee-eb15-d1e8e0de12cb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Statistics before imputation:\n",
            "         guests_per_bed  beds_per_bedroom  guests_per_bedroom\n",
            "mean          1.983956          1.225566            2.261351\n",
            "median        2.000000          1.000000            2.000000\n",
            "\n",
            "RE-CHECKING MISSINGNESS ON PRICE IMPUTATION DATAFRAME:\n",
            " accommodates    0\n",
            "bedrooms        0\n",
            "beds            0\n",
            "dtype: int64\n",
            "\n",
            "RE-CHECKING MISSINGNESS ON DROP PRICE DATAFRAME:\n",
            " accommodates    0\n",
            "bedrooms        0\n",
            "beds            0\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## CLEAN UP MISSING \"bathroom\" AND \"bathroom_text\" ATTRIBUTES"
      ],
      "metadata": {
        "id": "Ftrlg55IYzFH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Some properties are missing a number of bathrooms in the \"bathrooms\" attribute. Instead, it's stored as a string in the \"bathrooms_text\" attribute.\n",
        "\n",
        "# AGAIN, THIS RESULT COULD INDICATE A PATTERN OF MISSINGNESS, SINCE ROWS WITH MISSING PRICES ALSO HAVE OTHER MISSING ATTRIBUTES.\n",
        "# WE COULD CHECK IF THERE IS MISSINGNESS ACROSS, FOR EXAMPLE, A CERTAIN TYPE OF LISTING, THEN THE RESULTS WILL BE SKEWED.\n",
        "\n",
        "for name, df in datasets.items():\n",
        "  print(f\"CHECKING NULL COUNTS ON {name} DATAFRAME:\\n\", df[[\"bathrooms\", \"bathrooms_text\"]].isna().sum().to_frame(name=\"Null Count\"))\n",
        "  print(f\"\\nCHECKING MISSINGNESS ON {name} DATAFRAME:\\n\", df.loc[df[\"bathrooms\"].isna(),[\"bathrooms\",\"bathrooms_text\"]].head(10),\"\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GQGCWqkpYyoM",
        "outputId": "08ece696-f1db-46d8-cc92-184af4c89a70"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CHECKING NULL COUNTS ON drop_missing_prices DATAFRAME:\n",
            "                 Null Count\n",
            "bathrooms                2\n",
            "bathrooms_text           2\n",
            "\n",
            "CHECKING MISSINGNESS ON drop_missing_prices DATAFRAME:\n",
            "        bathrooms bathrooms_text\n",
            "106          NaN            NaN\n",
            "19459        NaN            NaN \n",
            "\n",
            "CHECKING NULL COUNTS ON impute_price DATAFRAME:\n",
            "                 Null Count\n",
            "bathrooms             2241\n",
            "bathrooms_text           2\n",
            "\n",
            "CHECKING MISSINGNESS ON impute_price DATAFRAME:\n",
            "      bathrooms bathrooms_text\n",
            "7          NaN      1.5 baths\n",
            "8          NaN  1 shared bath\n",
            "9          NaN      1.5 baths\n",
            "38         NaN         1 bath\n",
            "44         NaN         1 bath\n",
            "54         NaN         1 bath\n",
            "61         NaN         1 bath\n",
            "83         NaN         1 bath\n",
            "98         NaN         1 bath\n",
            "106        NaN            NaN \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# WE ARE DOING THE FOLLOWING ONLY ON THE PRICE IMPUTATION DF, SINCE THE DROP PRICE DF HAS ONLY 2 NULL VALUES.\n",
        "# Extract the numeric part from bathrooms_text\n",
        "bathrooms_from_text = (\n",
        "    df_price_imputation[\"bathrooms_text\"]\n",
        "    .astype(str)\n",
        "    .str.extract(r'(\\d+(\\.\\d+)?)')[0]   # capture integers or decimals\n",
        "    .astype(float)\n",
        ")\n",
        "\n",
        "# Fill missing values in bathrooms with extracted numbers\n",
        "df_price_imputation[\"bathrooms\"] = df_price_imputation[\"bathrooms\"].fillna(bathrooms_from_text)"
      ],
      "metadata": {
        "id": "HDANKDmEZ20f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_price_imputation[\"bathrooms\"].isna().sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BsTRHD5-e2Op",
        "outputId": "61a57249-9fe2-4519-ed88-348311c288ce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "np.int64(21)"
            ]
          },
          "metadata": {},
          "execution_count": 244
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# WE ARE DOING THE FOLLOWING ONLY ON THE PRICE IMPUTATION DF, SINCE THE DROP PRICE DF HAS ONLY 2 NULL VALUES.\n",
        "# Drop rest of missing values since the row count is so low\n",
        "\n",
        "df_price_imputation = df_price_imputation.dropna(subset=['bathrooms'])"
      ],
      "metadata": {
        "id": "n0RT_lzuewgv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_price_imputation[\"bathrooms\"].isna().sum()"
      ],
      "metadata": {
        "id": "Xo4Jm6TifyQH",
        "outputId": "f65c92e6-31e7-401e-a61e-02367c1b315d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "np.int64(0)"
            ]
          },
          "metadata": {},
          "execution_count": 246
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Show the pre results\n",
        "print(\"\\nCHECKING NULL COUNTS ON PRICE DROP DATAFRAME BEFORE:\\n\", df_drop_price[[\"bathrooms\", \"bathrooms_text\"]].isna().sum().to_frame(name=\"Null Count\"))\n",
        "\n",
        "# DROP THE 2 MISSING VALUES FOR THE DROP PRICE DATAFRAME\n",
        "df_drop_price = df_drop_price.dropna(subset=[\"bathrooms\"])\n",
        "df_drop_price = df_drop_price.dropna(subset=[\"bathrooms_text\"])\n",
        "\n",
        "# Show the post results\n",
        "print(\"\\nCHECKING NULL COUNTS ON PRICE DROP DATAFRAME AFTER:\\n\", df_drop_price[[\"bathrooms\", \"bathrooms_text\"]].isna().sum().to_frame(name=\"Null Count\"))"
      ],
      "metadata": {
        "id": "aH4lfkR7f07o",
        "outputId": "631f9d88-fd66-4034-fd93-a3f5ac7776a4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "CHECKING NULL COUNTS ON PRICE DROP DATAFRAME BEFORE:\n",
            "                 Null Count\n",
            "bathrooms                2\n",
            "bathrooms_text           2\n",
            "\n",
            "CHECKING NULL COUNTS ON PRICE DROP DATAFRAME AFTER:\n",
            "                 Null Count\n",
            "bathrooms                0\n",
            "bathrooms_text           0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## TRANSFORM \"description\" ATTRIBUTE BY ADDING \"description_missing\" AND \"description_length\" ATTRIBUTES"
      ],
      "metadata": {
        "id": "SOFawNzn8R0F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Description has some missing values\n",
        "for name, df in datasets.items():\n",
        "  print(f\"CHECK MISSING DESCRIPTION VALUE COUNT FOR {name} DATAFRAME:\\n\", df[\"description\"].isna().sum(),\"\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kkSO-oBS8Top",
        "outputId": "d9f1ab84-5e88-4161-d5cc-1c4a4b641baf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CHECK MISSING DESCRIPTION VALUE COUNT FOR drop_missing_prices DATAFRAME:\n",
            " 134 \n",
            "\n",
            "CHECK MISSING DESCRIPTION VALUE COUNT FOR impute_price DATAFRAME:\n",
            " 176 \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for name, df in datasets.items():\n",
        "  df['description_missing'] = df['description'].isna().astype(int) # Make flag for missing description\n",
        "  df['description_length'] = df['description'].fillna('').str.len() # Add description length\n",
        "\n",
        "# Show the results of adding the above columns\n",
        "for name, df in datasets.items():\n",
        "  print(f\"\\ndescription_missing HEAD FOR {name} DATAFRAME:\\n\", df['description_missing'].head(10))\n",
        "  print(f\"\\ndescription_length HEAD FOR {name} DATAFRAME:\\n\", df['description_length'].head(10))\n",
        "\n",
        "# We are now dropping the \"description\" attribute, as we no longer need it (we are not doing any text analysis).\n",
        "for name, df in datasets.items():\n",
        "  datasets[name] = df.drop(columns=[\"description\"])"
      ],
      "metadata": {
        "id": "e9_SK2cw8X0f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "24bf061d-f14f-43a8-80bc-3bb82a6d16e4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "description_missing HEAD FOR drop_missing_prices DATAFRAME:\n",
            " 2     0\n",
            "4     0\n",
            "5     0\n",
            "10    0\n",
            "14    0\n",
            "16    0\n",
            "17    0\n",
            "18    0\n",
            "21    1\n",
            "22    1\n",
            "Name: description_missing, dtype: int64\n",
            "\n",
            "description_length HEAD FOR drop_missing_prices DATAFRAME:\n",
            " 2     482\n",
            "4     412\n",
            "5      75\n",
            "10     54\n",
            "14    170\n",
            "16    290\n",
            "17    230\n",
            "18    352\n",
            "21      0\n",
            "22      0\n",
            "Name: description_length, dtype: int64\n",
            "\n",
            "description_missing HEAD FOR impute_price DATAFRAME:\n",
            " 2     0\n",
            "4     0\n",
            "5     0\n",
            "7     0\n",
            "8     0\n",
            "9     0\n",
            "10    0\n",
            "14    0\n",
            "16    0\n",
            "17    0\n",
            "Name: description_missing, dtype: int64\n",
            "\n",
            "description_length HEAD FOR impute_price DATAFRAME:\n",
            " 2     482\n",
            "4     412\n",
            "5      75\n",
            "7     558\n",
            "8     515\n",
            "9     471\n",
            "10     54\n",
            "14    170\n",
            "16    290\n",
            "17    230\n",
            "Name: description_length, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## TRANSFORM \"host_since\" ATTRIBUTE BY ADDING \"host_tenure_days\" ATTRIBUTE"
      ],
      "metadata": {
        "id": "O4Vocm0Z8h2v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Data has a host_since feature, so we use it to create a \"host_tenure_days\" column for each dataframe.\n",
        "\n",
        "for name, df in datasets.items():\n",
        "  df['host_since'] = pd.to_datetime(df['host_since'], errors='coerce')\n",
        "  latest_scrape = pd.to_datetime(df['last_scraped']).max() # Isolate the latest scrape date for calculation\n",
        "  df['host_tenure_days'] = (latest_scrape - df['host_since']).dt.days # Create new \"host_tenure_days\" attribute\n",
        "\n",
        "# Drop \"host_since\" and \"last_scraped\" columns\n",
        "for name, df in datasets.items():\n",
        "  datasets[name] = df.drop(columns=[\"host_since\", \"last_scraped\"])"
      ],
      "metadata": {
        "id": "RO9apSRT8kBd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for name, df in datasets.items():\n",
        "  print(f\"{name} results: \",df[\"host_tenure_days\"].isna().sum())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nbnQT1Fb8uue",
        "outputId": "b077de09-7801-4dab-cd27-8b9686778d92"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "drop_missing_prices results:  0\n",
            "impute_price results:  0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## TRANSFORM \"host_about\" ATTRIBUTE BY ADDING \"host_about_missing\" AND \"host_about_length\" ATTRIBUTES"
      ],
      "metadata": {
        "id": "nZN6lPWn83fX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for name, df in datasets.items():\n",
        "  df['host_about_missing'] = df['host_about'].isna().astype(int) # Make flag for host about\n",
        "  df['host_about_length'] = df['host_about'].fillna('').str.len() # Host about length\n",
        "\n",
        "# We are now dropping the \"host_about\" attribute, as we are not doing any text analysis\n",
        "for name, df in datasets.items():\n",
        "  datasets[name] = df.drop(columns=[\"host_about\"])"
      ],
      "metadata": {
        "id": "JzlfaWDS88tr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## TRANSFORM \"host_response_rate\" AND \"host_acceptance_rate\" BY ADDING \"...missing\" ATTRIBUTES"
      ],
      "metadata": {
        "id": "ty9yKcxo9Koo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Format as float, add missing flag, fill with median\n",
        "\n",
        "for name, df in datasets.items():\n",
        "  for col in [\"host_response_rate\", \"host_acceptance_rate\"]:\n",
        "      temp = df[col].astype(str).str.strip().str.rstrip('%').replace('', np.nan)\n",
        "      df[col] = pd.to_numeric(temp, errors='coerce')\n",
        "      df[f\"{col}_missing\"] = df[col].isna().astype(int)\n",
        "      df[col] = df[col].fillna(df[col].median())"
      ],
      "metadata": {
        "id": "s8RKLNx59NKV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## TRANSFORM \"host_response_time\" ATTRIBUTE BY ADDING CATEGORY FOR MISSING VALUES CALLED \"unknown\""
      ],
      "metadata": {
        "id": "DFPeo21O9zTZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Response time is a category\n",
        "# Fill unknown or missing response time with category \"unknown\"\n",
        "\n",
        "for name, df in datasets.items():\n",
        "  df['host_response_time'] = df['host_response_time'].fillna('unknown')"
      ],
      "metadata": {
        "id": "cf3LCsRc91De"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## TRANSFORM \"neighborhood_overview\" ATTRIBUTE BY ADDING \"neighborhood_overview_length\" AND \"neighborhood_overview_missing\" ATTRIBUTES"
      ],
      "metadata": {
        "id": "zN7sj4IcEmZ7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for name, df in datasets.items():\n",
        "  df['neighborhood_overview_missing'] = df['neighborhood_overview'].isna().astype(int) # Make flag for neighboorhood overview\n",
        "  df['neighborhood_overview_length'] = df['neighborhood_overview'].fillna('').str.len() # Neighborhood overview length\n",
        "\n",
        "# We are now dropping the \"neighborhood_overview\" attribute, as we are not doing any text analysis\n",
        "for name, df in datasets.items():\n",
        "  df.drop(columns=[\"neighborhood_overview\"], inplace=True)\n",
        "\n",
        "# Print results\n",
        "for name, df in datasets.items():\n",
        "  print(f\"{name} results: \",df[[\"neighborhood_overview_missing\",\"neighborhood_overview_length\"]].isna().sum())"
      ],
      "metadata": {
        "id": "fMrZaqQHEmy5",
        "outputId": "e1da5adb-2719-428d-b0e0-b98887ca843d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "drop_missing_prices results:  neighborhood_overview_missing    0\n",
            "neighborhood_overview_length     0\n",
            "dtype: int64\n",
            "impute_price results:  neighborhood_overview_missing    0\n",
            "neighborhood_overview_length     0\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "list(df_drop_price)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XXNs9rVdd5_6",
        "outputId": "f08a040b-637c-4577-f48c-757db3da14da"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['last_scraped',\n",
              " 'description',\n",
              " 'neighborhood_overview',\n",
              " 'host_since',\n",
              " 'host_location',\n",
              " 'host_about',\n",
              " 'host_response_time',\n",
              " 'host_response_rate',\n",
              " 'host_acceptance_rate',\n",
              " 'host_is_superhost',\n",
              " 'host_has_profile_pic',\n",
              " 'host_identity_verified',\n",
              " 'neighbourhood_cleansed',\n",
              " 'latitude',\n",
              " 'longitude',\n",
              " 'property_type',\n",
              " 'room_type',\n",
              " 'accommodates',\n",
              " 'bathrooms',\n",
              " 'bathrooms_text',\n",
              " 'bedrooms',\n",
              " 'beds',\n",
              " 'amenities',\n",
              " 'price',\n",
              " 'minimum_nights',\n",
              " 'maximum_nights',\n",
              " 'availability_30',\n",
              " 'number_of_reviews',\n",
              " 'instant_bookable',\n",
              " 'calculated_host_listings_count']"
            ]
          },
          "metadata": {},
          "execution_count": 256
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## TRANSFORM \"host_location\" ATTRIBUTE BY ADDING \"host_location_missing\" ATTRIBUTE"
      ],
      "metadata": {
        "id": "vSz6N5qjHEV0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for name, df in datasets.items():\n",
        "  df['host_location_missing'] = df['host_location'].isna().astype(int) # Make flag for host location\n",
        "\n",
        "# We are now dropping the \"host_location\" attribute, as we are not doing any text analysis\n",
        "for name, df in datasets.items():\n",
        "  df.drop(columns=[\"host_location\"], inplace=True)\n",
        "\n",
        "# Print results\n",
        "for name, df in datasets.items():\n",
        "  print(f\"{name} results: \",df[[\"host_location_missing\"]].isna().sum())"
      ],
      "metadata": {
        "id": "snoFSDaoHNEP",
        "outputId": "47cabe77-85e3-43eb-8991-eca279597f47",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 561
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "'host_location'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3804\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3805\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3806\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mindex.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mindex.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'host_location'",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-992645623.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m   \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'host_location_missing'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'host_location'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Make flag for host location\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# We are now dropping the \"host_location\" attribute, as we are not doing any text analysis\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4100\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4101\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4102\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4103\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4104\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3810\u001b[0m             ):\n\u001b[1;32m   3811\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mInvalidIndexError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3812\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3813\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3814\u001b[0m             \u001b[0;31m# If we have a listlike key, _check_indexing_error will raise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'host_location'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_drop_price.sort_values(by=\"price\", ascending=True).head(10)\n",
        "df_drop_price.shape"
      ],
      "metadata": {
        "id": "68TBxyO-JG8b",
        "outputId": "244cede8-54e5-4dba-c71d-12e4ea43bab7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(7632, 30)"
            ]
          },
          "metadata": {},
          "execution_count": 224
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## [TEMP] DROP COLUMNS THAT WE WILL COME BACK TO LATER"
      ],
      "metadata": {
        "id": "XMpcxAXGZxpL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "list(df_drop_price)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7gg_dUoaZ3Dg",
        "outputId": "aeaf7314-a31a-498c-c2c0-e00d9ca3a0af"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['last_scraped',\n",
              " 'description',\n",
              " 'neighborhood_overview',\n",
              " 'host_since',\n",
              " 'host_location',\n",
              " 'host_about',\n",
              " 'host_response_time',\n",
              " 'host_response_rate',\n",
              " 'host_acceptance_rate',\n",
              " 'host_is_superhost',\n",
              " 'host_has_profile_pic',\n",
              " 'host_identity_verified',\n",
              " 'neighbourhood_cleansed',\n",
              " 'latitude',\n",
              " 'longitude',\n",
              " 'property_type',\n",
              " 'room_type',\n",
              " 'accommodates',\n",
              " 'bathrooms',\n",
              " 'bathrooms_text',\n",
              " 'bedrooms',\n",
              " 'beds',\n",
              " 'amenities',\n",
              " 'price',\n",
              " 'minimum_nights',\n",
              " 'maximum_nights',\n",
              " 'availability_30',\n",
              " 'number_of_reviews',\n",
              " 'instant_bookable',\n",
              " 'calculated_host_listings_count']"
            ]
          },
          "metadata": {},
          "execution_count": 225
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## CREATE HEX BINS FROM LONG/LAT TO ADD A MORE GRANULAR LOCATION ATTRIBUTE"
      ],
      "metadata": {
        "id": "3otU4nvDBx6_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Neighborhood data is not very granular\n",
        "# Long and lat used to create hexbins\n",
        "\n",
        "import geopandas as gpd\n",
        "from shapely.geometry import Point, Polygon\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# --- 1. Create GeoDataFrame from lat / lon ---\n",
        "\n",
        "gdf = gpd.GeoDataFrame(\n",
        "    df.copy(),\n",
        "    geometry=gpd.points_from_xy(df[\"longitude\"], df[\"latitude\"]),\n",
        "    crs=\"EPSG:4326\"   # WGS84 (lat/lon)\n",
        ")\n",
        "\n",
        "# Project to a metric CRS (UTM zone – here: 32N, good for Denmark/southern Sweden)\n",
        "gdf = gdf.to_crs(epsg=32632)\n",
        "\n",
        "\n",
        "# --- 2. Helper: build a single regular hexagon around a center ---\n",
        "\n",
        "def make_hexagon(cx, cy, radius):\n",
        "    \"\"\"\n",
        "    Create a pointy-top regular hexagon centered at (cx, cy)\n",
        "    with given radius (distance from center to each vertex).\n",
        "    \"\"\"\n",
        "    # Pointy-top: start at 30° and step by 60°\n",
        "    angles = np.deg2rad(np.arange(0, 360, 60) + 30)\n",
        "    coords = [(cx + radius * np.cos(a), cy + radius * np.sin(a)) for a in angles]\n",
        "    return Polygon(coords)\n",
        "\n",
        "\n",
        "# --- 3. Build a hex grid over the extent of gdf ---\n",
        "\n",
        "def make_hex_grid(gdf, radius):\n",
        "    \"\"\"\n",
        "    Create a pointy-top hexagon grid covering the extent of gdf.\n",
        "    radius = distance from hex center to each vertex (in CRS units, e.g. meters).\n",
        "    \"\"\"\n",
        "    xmin, ymin, xmax, ymax = gdf.total_bounds\n",
        "\n",
        "    # Pointy-top spacing (Red Blob Games):\n",
        "    # horizontal distance between centers = sqrt(3) * radius\n",
        "    # vertical distance between rows = 1.5 * radius\n",
        "    dx = np.sqrt(3) * radius\n",
        "    dy = 1.5 * radius\n",
        "\n",
        "    cols = np.arange(xmin - dx, xmax + dx, dx)\n",
        "    rows = np.arange(ymin - dy, ymax + dy, dy)\n",
        "\n",
        "    hexes = []\n",
        "    for row_idx, cy in enumerate(rows):\n",
        "        for col_idx, cx in enumerate(cols):\n",
        "            # Offset every second row by half the horizontal spacing\n",
        "            cx_shifted = cx + (dx / 2.0 if row_idx % 2 == 1 else 0.0)\n",
        "            hex_poly = make_hexagon(cx_shifted, cy, radius)\n",
        "            hexes.append(hex_poly)\n",
        "\n",
        "    hex_grid = gpd.GeoDataFrame(\n",
        "        {\"hex_id\": range(len(hexes))},\n",
        "        geometry=hexes,\n",
        "        crs=gdf.crs\n",
        "    )\n",
        "    return hex_grid\n",
        "\n",
        "\n",
        "# --- 4. Generate hex grid + optional trimming ---\n",
        "\n",
        "hex_radius = 250  # meters\n",
        "hex_grid = make_hex_grid(gdf, hex_radius)\n",
        "\n",
        "# Optional trimming to a buffered convex hull of listings\n",
        "study_area = gdf.geometry.union_all().convex_hull.buffer(2 * hex_radius)\n",
        "hex_grid = hex_grid[hex_grid.intersects(study_area)].reset_index(drop=True)\n",
        "hex_grid[\"hex_id\"] = hex_grid.index  # reindex after trimming\n",
        "\n",
        "# --- 5. Spatial join: assign each listing to a hex ---\n",
        "\n",
        "joined = gpd.sjoin(\n",
        "    gdf,\n",
        "    hex_grid[[\"hex_id\", \"geometry\"]],\n",
        "    how=\"left\",\n",
        "    predicate=\"within\"   # use \"intersects\" if you see edge-cases\n",
        ")\n",
        "\n",
        "# Join hex_id to the original df\n",
        "\n",
        "merged = df.merge(joined[[\"id\", \"hex_id\"]], on=\"id\")\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "k6i9qRlWOb8X",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 329
        },
        "outputId": "a35a9d56-cff1-4c5c-db28-199f287d053e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "\"['id'] not in index\"",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1730642063.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[0;31m# Join hex_id to the original df\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m \u001b[0mmerged\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmerge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjoined\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"id\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"hex_id\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mon\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"id\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/geopandas/geodataframe.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1894\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0ma\u001b[0m \u001b[0mGeoDataFrame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1895\u001b[0m         \"\"\"\n\u001b[0;32m-> 1896\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1897\u001b[0m         \u001b[0;31m# Custom logic to avoid waiting for pandas GH51895\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1898\u001b[0m         \u001b[0;31m# result is not geometry dtype for multi-indexes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4106\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4107\u001b[0m                 \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4108\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_indexer_strict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"columns\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4110\u001b[0m         \u001b[0;31m# take() does not accept boolean indexers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36m_get_indexer_strict\u001b[0;34m(self, key, axis_name)\u001b[0m\n\u001b[1;32m   6198\u001b[0m             \u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_indexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reindex_non_unique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6199\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6200\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_raise_if_missing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6201\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6202\u001b[0m         \u001b[0mkeyarr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36m_raise_if_missing\u001b[0;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[1;32m   6250\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6251\u001b[0m             \u001b[0mnot_found\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mensure_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmissing_mask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnonzero\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6252\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{not_found} not in index\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6253\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6254\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0moverload\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: \"['id'] not in index\""
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Visualization: check that hexes look like hexes ---\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(8, 8))\n",
        "\n",
        "# plot hex outlines\n",
        "hex_grid.boundary.plot(ax=ax, linewidth=0.5)\n",
        "\n",
        "# plot listing points\n",
        "gdf.plot(ax=ax, markersize=3, color=\"red\", alpha=0.7)\n",
        "\n",
        "ax.set_title(\"Listings and true hex grid\")\n",
        "ax.set_axis_off()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "2wDJeMUii8yD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Mapping hexes"
      ],
      "metadata": {
        "id": "_cXkDpNzOE5E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import folium\n",
        "\n",
        "# Convert hexes and points to WGS84 (lat/lon)\n",
        "hex_wgs = hex_grid.to_crs(epsg=4326)\n",
        "pts_wgs = gdf.to_crs(epsg=4326)\n",
        "\n",
        "center_lat = pts_wgs.geometry.y.mean()\n",
        "center_lon = pts_wgs.geometry.x.mean()\n",
        "\n",
        "m = folium.Map(location=[center_lat, center_lon], zoom_start=11)\n",
        "\n",
        "folium.GeoJson(\n",
        "    hex_wgs,\n",
        "    name=\"Hex grid\",\n",
        "    style_function=lambda feature: {\n",
        "        \"fillColor\": \"none\",\n",
        "        \"color\": \"blue\",\n",
        "        \"weight\": 1,\n",
        "        \"fillOpacity\": 0.1,\n",
        "    },\n",
        ").add_to(m)\n",
        "\n",
        "sample_pts = pts_wgs.sample(min(2000, len(pts_wgs)), random_state=0)\n",
        "\n",
        "for _, row in sample_pts.iterrows():\n",
        "    folium.CircleMarker(\n",
        "        location=[row.geometry.y, row.geometry.x],\n",
        "        radius=2,\n",
        "        color=\"red\",\n",
        "        fill=True,\n",
        "        fill_opacity=0.7,\n",
        "    ).add_to(m)\n",
        "\n",
        "m"
      ],
      "metadata": {
        "id": "PPo6hfQyHSNz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# PLACEHOLDER FOR MODELING"
      ],
      "metadata": {
        "id": "zsnj8tLGfToY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --------------------------------------------------\n",
        "# 0. Wrap your two datasets in a dictionary - NOTE TO GROUP: VALIDATE THAT THE 2 DATASETS WORK, OR PROCEED WITH JUST 1 AT A TIME.\n",
        "# --------------------------------------------------\n",
        "datasets = {\n",
        "    \"price_imputation\": df_price_imputation,\n",
        "    \"drop_price\": df_drop_price,\n",
        "}\n",
        "\n",
        "# Replace this with the actual column name in your data\n",
        "target_col = \"occupancy_30\"   # e.g. number of booked days in next 30\n",
        "\n",
        "# --------------------------------------------------\n",
        "# 1. Define candidate models (supervised regressors) - NOTE TO GROUP: ANY OTHER MODELS TO CONSIDER?\n",
        "# --------------------------------------------------\n",
        "models = {\n",
        "    \"LinearRegression\": LinearRegression(),\n",
        "    \"Ridge\": Ridge(),\n",
        "    \"Lasso\": Lasso(),\n",
        "    \"KNN\": KNeighborsRegressor(),\n",
        "    \"DecisionTree\": DecisionTreeRegressor(),\n",
        "    \"RandomForest\": RandomForestRegressor(),\n",
        "    \"GradientBoosting\": GradientBoostingRegressor(),\n",
        "}\n",
        "\n",
        "# --------------------------------------------------\n",
        "# 2. Define hyperparameter grids for each model - NOTE TO GROUP: GET THE PIPELINE TO CONSIDER ALL HYPERPARAMETERS INSTEAD OF JUST ARBITRARY NUMBERS\n",
        "# --------------------------------------------------\n",
        "param_grids = {\n",
        "    \"LinearRegression\": {},  # no hyperparameters\n",
        "\n",
        "    \"Ridge\": {\n",
        "        \"model__alpha\": [0.1, 1.0, 10.0],\n",
        "    },\n",
        "\n",
        "    \"Lasso\": {\n",
        "        \"model__alpha\": [0.001, 0.01, 0.1],\n",
        "    },\n",
        "\n",
        "    \"KNN\": {\n",
        "        \"model__n_neighbors\": [3, 5, 7, 15],\n",
        "        \"model__weights\": [\"uniform\", \"distance\"],\n",
        "    },\n",
        "\n",
        "    \"DecisionTree\": {\n",
        "        \"model__max_depth\": [3, 5, 10, None],\n",
        "        \"model__min_samples_split\": [2, 10, 30],\n",
        "    },\n",
        "\n",
        "    \"RandomForest\": {\n",
        "        \"model__n_estimators\": [100, 300],\n",
        "        \"model__max_depth\": [5, 10, None],\n",
        "    },\n",
        "\n",
        "    \"GradientBoosting\": {\n",
        "        \"model__learning_rate\": [0.01, 0.1],\n",
        "        \"model__n_estimators\": [100, 200],\n",
        "    },\n",
        "}\n",
        "\n",
        "# --------------------------------------------------\n",
        "# 3. Run the full pipeline for each dataset -\n",
        "# --------------------------------------------------\n",
        "all_results = []\n",
        "\n",
        "for ds_name, df in datasets.items():\n",
        "    print(f\"\\n================ {ds_name} ================\\n\")\n",
        "\n",
        "    # --- 3.1 Split into features (X) and target (y)\n",
        "    X = df.drop(columns=[target_col])\n",
        "    y = df[target_col]\n",
        "\n",
        "    # --- 3.2 Train/test split\n",
        "    X_train, X_test, y_train, y_test = train_test_split(\n",
        "        X, y, test_size=0.2, random_state=42\n",
        "    )\n",
        "\n",
        "    # --- 3.3 Identify numeric vs categorical columns\n",
        "    numeric_cols = X_train.select_dtypes(include=[np.number]).columns.tolist()\n",
        "    categorical_cols = X_train.select_dtypes(\n",
        "        include=[\"object\", \"category\"]\n",
        "    ).columns.tolist()\n",
        "\n",
        "    # --- 3.4 Preprocessing: scaling + one-hot encoding\n",
        "    preprocess = ColumnTransformer(\n",
        "        transformers=[\n",
        "            (\"num\", StandardScaler(), numeric_cols),\n",
        "            (\"cat\", OneHotEncoder(handle_unknown=\"ignore\"), categorical_cols),\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    # --- 3.5 Loop over models and run GridSearchCV\n",
        "    for model_name, model in models.items():\n",
        "        print(f\"Fitting model: {model_name} on {ds_name}...\")\n",
        "\n",
        "        pipe = Pipeline(steps=[\n",
        "            (\"preprocess\", preprocess),\n",
        "            (\"model\", model),\n",
        "        ])\n",
        "\n",
        "        grid = GridSearchCV(\n",
        "            estimator=pipe,\n",
        "            param_grid=param_grids[model_name],\n",
        "            cv=5,\n",
        "            scoring=\"neg_mean_absolute_error\",\n",
        "            n_jobs=-1,\n",
        "        )\n",
        "\n",
        "        grid.fit(X_train, y_train)\n",
        "\n",
        "        best_model = grid.best_estimator_\n",
        "\n",
        "        # --- 3.6 Evaluate on test set\n",
        "        y_pred = best_model.predict(X_test)\n",
        "\n",
        "        mae = mean_absolute_error(y_test, y_pred)\n",
        "        rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
        "\n",
        "        # Guard against division by zero in MAPE\n",
        "        non_zero_mask = y_test != 0\n",
        "        if non_zero_mask.sum() > 0:\n",
        "            mape = np.mean(\n",
        "                np.abs((y_test[non_zero_mask] - y_pred[non_zero_mask]) / y_test[non_zero_mask])\n",
        "            ) * 100\n",
        "        else:\n",
        "            mape = np.nan\n",
        "\n",
        "        all_results.append({\n",
        "            \"Dataset\": ds_name,\n",
        "            \"Model\": model_name,\n",
        "            \"Best Params\": grid.best_params_,\n",
        "            \"MAE\": mae,\n",
        "            \"RMSE\": rmse,\n",
        "            \"MAPE\": mape,\n",
        "        })\n",
        "\n",
        "# --------------------------------------------------\n",
        "# 4. Collect and inspect results\n",
        "# --------------------------------------------------\n",
        "results_df = pd.DataFrame(all_results)\n",
        "results_df = results_df.sort_values(by=[\"Dataset\", \"MAE\"])\n",
        "print(results_df)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "## WE NEED TO CONSIDER EVALUATING OUR MODEL ON WHETHER OR NOT IT PERFORMS BETTER/WORSE FOR CERTAIN TYPES LISTINGS (E.G., LESS ACCURATE FOR LISTINGS WITH HIGHER)\n",
        "\n",
        "## REDO DATA WRANGLING TO USE ONE DATASET UNTIL WE REACH PRICE, THEN DO THE SPLIT\n",
        "\n",
        "## FIX HEXBIN LOCATION VARIABLE\n",
        "\n",
        "## FIGURE OUT AMENITIES VARIABLE\n"
      ],
      "metadata": {
        "id": "fSkIdf3ZfXk9"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}